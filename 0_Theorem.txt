지금까지 배운 웹 스크래핑 내용을 정리하는 시간을 가져보자


HTML 은 뼈대, CSS 예쁘게, JS는 살아있게


XPath 는 Element의 경로를 의미한다. 어떤 특징을 가진 tag를 element로 하여금 지정한 경로 -> //*[@id="search_btn"]
때로는 전체경로를 이용해야 할 때가 있다. 경로는 Chrome의 copy에서 가볍게 가져 올 수 있었다.


정규식 : 규칙을 가진 문자열의 표현하는 식
. : 하나의 문자  ,  ^ : 문자열의 시작  ,  $ : 문자열의 끝
match() : 처음부터 일치하는지  ,  search() : 일치하는 게 있는지  ,  findall() : 일치하는 것 모두 리스트로


User-Agent : client의 클릭으로 브라우져가 웹페이지를 요청할 때 전달하는 header의 내용을 바탕으로
    서버에서는 어떤 페이지를 보여줄 지를 결정을 한다 (예 : 스마트폰은 모바일전용, PC는 데스크탑전용)
    일반적인 정보가 아닐때는 서버에서 접속을 막거나 권한을 주지 않을 수 있는데, 
    이때 우리는 "저 사람맞아요~"의 표시를 user-agent로 표시 할 수 있다.



Requests : 웹페이지를 읽어올 때 사용한다. 빠르지만 동적 웹페이지에서는 사용이 불가능 하다
Selenium : 웹페이지를 자동화 할 수 있는 프레임워크이다. 느리고 메모리를 많이 먹는다는 단점이 존재하지만
    동적인 웹페이지에 대하여 글자 삽입, 버튼 클릭, 데이터가져오기 등의 다양한 기능을 제공한다.
이 두가지는 결국 HTML문서를 가져오는 방법의 차이일 뿐이다.
그리고 이렇게 가져온 데이터를 BeautifulSoup을 이용해서 추출을 하는 것이다. 
BeautifulSoup : 원하는 데이터추출(웹 스크래핑)


Request : 주어진 url을 통해 받아온 html에 원하는 정보가 있을 때 사용하면 굉장히좋다.
    그리고 문제가 없다면 이용할 수 있도록 res.raise_for_status()를 이용하였다.

Selenium : 로그인이나 어떤 결과에 대한 필터링 등 어떤 동작을 해야하는 경우 굉장히 좋다
    ★★★크롬의 경우 크롬 버전에 맞는 chromedriver.exe 가 반드시 있어야한다.★★★
    id, class name, link text, xpath로 찾고 elements의 경우 find_all과 같이 전부다 가져온다.
    clink, send_keys(), clear() 의 기능도 제공한다.

    Selenium의 경우 때로는 기다려줘야하는 경우(로딩) 가 발생하기도 한다.
    이때는 WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, "//*[@id='content']")))
    브라우져를 최대 10초까지는 기다리는데, XPATH기준으로 해당 XPATH가 화면에 위치할 때 까지 기다리게 하거나 time를 사용

    자동으로 스크롤을 내려주는 코드또한 존재한다.
    browser.execute_script("return document.body.scrollHeight") : 현재 문서높이를 반환
    browser.execute_script("window.scrollTo(0, document.body.scrollHeight)") : 스크롤을 창 높이만큼 내린다.

BeautifulSoup : 조건에 맞는 element, elements를 가져오는 기능 
        find_next_sibling(s) : 다음 형제 찾기
        find_previous_sibling(s) : 이전 형제 찾기
        soup.get_text() : 텍스트 반환
        soup["href"] : 속성 반환



이미지와 CSV파일을 쓰는 방법도 익혔다. 
이미지의 경우 wb형식으로 사용하고, csv의 경우 excel로 읽을 경우 encoding="utf-8-sig"를 사용하고, newline=''로 설정한다.



Headless Chrome
브라우저를 띄우지 않고 동작, 때로는 User-Agent 정의가 필요, 59버전부터 가능 (최신버전이면 모두 가능)



★★★주의★★★
막쓰면 안돼요
무분별한 웹 크롤링/ 웹 스크래핑은 대상 서버에 부하 --> 계정 / IP차단
데이터 사용 주의 --> 이미지, 텍스트 등 데이터 무단 활용 시 저작권 등 침해요소, 법적 제재
페이지 마다 robots.txt 파일을 제공하는데 --> 법적 효력X, 대상 사이트의 권고 (이런 데이터는 가져가지 마세요)

